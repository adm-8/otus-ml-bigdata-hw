{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                         \n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mscala.collection.mutable.ArrayBuffer\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mbreeze.linalg._\u001b[39m"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// подключаем необходимые библиотеки\n",
    "import $ivy.`org.scalanlp::breeze:1.0`\n",
    "import scala.collection.mutable.ArrayBuffer\n",
    "import breeze.linalg._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// читаем файл с данными\n",
    "val dataFile = io.Source.fromFile(\"Dataset.csv\")\n",
    "\n",
    "// подготавливаем матрицу\n",
    "var dataMatrix = DenseMatrix.zeros[Double](0,28)\n",
    "\n",
    "var i = 0\n",
    "// Пробегаемся по каждай строке файла\n",
    "for (line <- dataFile.getLines.drop(1)) { \n",
    "    \n",
    "    // готовим массив для дальнейшего его перегона в матрицу \n",
    "    var dataArray = Array[Double]()\n",
    "    \n",
    "    // делим строку на элементы и обрезаем пробелы\n",
    "    for (elem <- line.split(\",\")map(_.trim)){\n",
    "        // если значения нет, то добавляем 0\n",
    "        if(elem == \"\") {\n",
    "            dataArray = dataArray :+ 0.0 \n",
    "        // иначе добавляем в массив значение елемента\n",
    "        }else{\n",
    "            dataArray = dataArray :+ elem.toDouble\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    // наполняем матрицу\n",
    "    dataMatrix = DenseMatrix.vertcat(dataMatrix, DenseMatrix(DenseVector(dataArray)))\n",
    "    i += 1 // без счетчика у меня напроч умирал юпитер, видимо потому, что пытался вывести все значения матрицы \n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// разбиваем данные\n",
    "val X_all = dataMatrix(0 to dataMatrix.rows - 1, 0 to dataMatrix.cols-2)\n",
    "val Y_all = dataMatrix(::,27)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Посмотрим на корреляцию в данных (не осилил это сделать в скале, сделал через LibreOffice)\n",
    "\n",
    "##### для удобства разбил на две матрицы корреляции, чтобы нормально влезло в экран\n",
    "\n",
    "![title](dataset_corr.png)\n",
    "\n",
    "\n",
    "Как мы можем заметить, самая высока степерь корреляции с целевым признаком output у признака **comm24**. Далее по списку идут: **diff2448 , comm24_1 , commBase**. Их и будем использовать в качестве описываемых признаков.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// вырезаем необходимые признаки (4,5,7,8) и собираем новую матрцу\n",
    "\n",
    "val X_commBase = DenseMatrix(X_all(::,4))\n",
    "val X_comm24 = DenseMatrix(X_all(::,5))\n",
    "val X_comm24_1 = DenseMatrix(X_all(::,7))\n",
    "val X_diff2448 = DenseMatrix(X_all(::,8))\n",
    "var X = DenseMatrix.zeros[Double](X_commBase(::,0).length,0)\n",
    "\n",
    "X = DenseMatrix.horzcat(X_commBase.t, X_comm24.t)\n",
    "X = DenseMatrix.horzcat(X, X_comm24_1.t)\n",
    "X = DenseMatrix.horzcat(X, X_diff2448.t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "// Проверяем, что размерности не поехали\n",
    "X.rows\n",
    "X.cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// разделим выборки на train и test\n",
    "val test_count = (X.rows * 0.67).toInt\n",
    "val X_train = X(0 to test_count, 0 to X.cols - 1)\n",
    "val X_test = X(test_count to X.rows - 1, 0 to X.cols - 1)\n",
    "val Y_train = Y_all(0 to test_count)\n",
    "val Y_test = Y_all(test_count to Y_all.length - 1)\n",
    "assert(X_train.rows == Y_train.length)\n",
    "assert(X_test.rows == Y_test.length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// применяем регрессионные модели на 4х колонках\n",
    "import breeze.stats.regression.{leastSquares, lasso}\n",
    "val squaresModel = leastSquares(X_train, Y_train)\n",
    "val lassoModel = lasso(X_train, Y_train, 0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// применим наши модели на тестовой выборке\n",
    "\n",
    "assert(X_test.cols == squaresModel.coefficients.length)\n",
    "val Y_pred_squaresModel = X_test * squaresModel.coefficients\n",
    "val Y_pred_lassoModel = X_test * lassoModel.coefficients\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### В качестве функции потерь будем использовать MAE т.к. нам необходимо понимать, на сколько комментариев мы промахиваемся в ту или иную сторону"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math.abs\n",
    "val mae = (X: DenseVector[Double], X_pred: DenseVector[Double]) => {\n",
    "    ((X - X_pred).map(x => abs(x)).sum) / X.length\n",
    "}\n",
    "\n",
    "val mae_test_squaresModel = mae(Y_test, Y_pred_squaresModel)\n",
    "val mae_test_lassoModel = mae(Y_test, Y_pred_lassoModel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Судя по результатам оценки, lassoModel показывает немного большую точность чем squaresModel на текущих данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Вычислим коэфиценты своими силами и сравним результаты\n",
    "\n",
    "### Т.к. данных у нас не так много, можно использовать самую простую реализацию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import breeze.linalg.inv\n",
    "val X_train_t = X_train.t\n",
    "val coef_custom = inv((X_train_t * X_train)) * X_train_t * Y_train\n",
    "var Y_pred_custom = X_test * coef_custom\n",
    "val mae_test_custom = mae(Y_test, Y_pred_custom)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Итоговые значения средних абсолютных ошибок: \n",
    "\n",
    "* lassoModel = 5.984693119061619\n",
    "* squaresModel = 6.231902929890508\n",
    "* custom = 6.231902929890598\n",
    "\n",
    "Кастомная реализация показала практически тот же результат, что и squaresModel. В целом не плохо. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala 2.13",
   "language": "scala",
   "name": "scala213"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".sc",
   "mimetype": "text/x-scala",
   "name": "scala",
   "nbconvert_exporter": "script",
   "version": "2.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
